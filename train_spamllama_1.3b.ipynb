{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGE_COLUMN = '전문내용'\n",
    "RESULT_COLUMN = 'chatGPT'\n",
    "PROMPT_COLUMN = '프롬프트'\n",
    "# PROMPT_COLUMN = 'prompt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQ_FILE = './spamllama_dataset.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEXT = \"\"\"{Role: 너는 SMS 문자 메시지를 보고 그 메시지가 왜 악성스팸인지를 판정하는 악성스팸 분석가로서 분석 결과를 말할 때 원문을 다시 말하지는 않고 분석 결과에 대해서는 풍부하게 말하는 분석가이다.}\n",
    "{Condition: 모든 분석 대상 문자 메시지는 수신자가 해당 서비스나 정보에 관심이 없는 경우이거나 해당 서비스에 가입한 적이 없기 때문에 대부분 악성 스팸이다.\n",
    "            다음 SMS 문자 메시지를 분석하여 그것이 어떤 부류의 악성 스팸인지 설명하고, 얼마나 위험한지 다음 보기에서만 골라라.\n",
    "            1)50~70%, 2) 70~80%, 3) 80~90%, 4) 90~95%, 5) 95~100%. 위험 정도에 대해 반드시 언급하고 그 이유를 충분히 설명하라. }\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c51bd1dce9404e97c475b32ae2cd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['전문내용', 'chatGPT'],\n",
      "    num_rows: 1649\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a0f9709132458f8276888896cac300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1649 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = Dataset.from_parquet(PARQ_FILE)\n",
    "print(data)\n",
    "data = data.map(\n",
    "    lambda x: {'text': f\"### 프롬프트: {PROMPT_TEXT}\\n\\n ### 질문: {x[MESSAGE_COLUMN]}\\n\\n### 답변: {x[RESULT_COLUMN]}<|endoftext|>\" }\n",
    "    # lambda x: {'text': f\"### 프롬프트: {x[PROMPT_COLUMN]}\\n\\n ### 질문: {x[MESSAGE_COLUMN]}\\n\\n### 답변: {x[RESULT_COLUMN]}<|endoftext|>\" }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aba17ca962440de832aebc50cc7b978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc837f2626894ae6888fe32312b04078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/1.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee9b914f42a45308437963f3eeaef6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4b3a478b2d45deb899b7431f999f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/748M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fd6c5d623046e39fc16264c709341c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f438f30063084ff39cc02d01cc10380a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# model_id = \"beomi/polyglot-ko-12.8b-safetensors\"  # safetensors 컨버팅된 레포]\n",
    "# model_id = \"ch2vod/spamllama\"  # safetensors 컨버팅된 레포\n",
    "model_id = \"EleutherAI/polyglot-ko-1.3b\"  # safetensors 컨버팅된 레포\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033b58fbc6a74808a8308ab55a4d6a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1649 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "# needed for gpt-neo-x tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        # max_steps=1000, ## 초소량만 학습: 50 step만 학습. 약 4분정도 걸립니다.\n",
    "        num_train_epochs=12,\n",
    "        learning_rate=1e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to Huggingface\n",
    "ACCESS_TOKEN = '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'\n",
    "\n",
    "# model.push_to_hub('ch2vod/spamllama', use_temp_dir=True, use_auth_token=ACCESS_TOKEN)\n",
    "# tokenizer.push_to_hub('ch2vod/spamllama', use_temp_dir=True, use_auth_token=ACCESS_TOKEN)\n",
    "model.push_to_hub('ch2vod/spamllama_1.3b', use_temp_dir=True, use_auth_token=ACCESS_TOKEN)\n",
    "tokenizer.push_to_hub('ch2vod/spamllama_1.3b', use_temp_dir=True, use_auth_token=ACCESS_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.config.use_cache = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x):\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            f\"### 질문: {x}\\n\\n### 답변:\",\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ),\n",
    "        max_new_tokens=256,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(tokenizer.decode(gened[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen('### 프롬프트: {Role: 너는 SMS 문자 메시지를 보고 그 메시지가 왜 악성스팸인지를 판정하는 악성스팸 분석가로서 분석 결과를 말할 때 원문을 다시 말하지는 않고 분석 결과에 대해서는 풍부하게 말하는 분석가이다.}\\n{Condition: 모든 분석 대상 문자 메시지는 수신자가 해당 서비스나 정보에 관심이 없는 경우이거나 해당 서비스에 가입한 적이 없기 때문에 대부분 악성 스팸이다.\\n            다음 SMS 문자 메시지를 분석하여 그것이 어떤 부류의 악성 스팸인지 설명하고, 얼마나 위험한지 다음 보기에서만 골라라.\\n            3)50~70%, 2) 70~80%, 3) 80~90%, 4) 90~95%, 5) 95~100%. 위험 정도에 대해 반드시 언급하고 그 이유를 충분히 설명하라. }\\n\\n ### 질문: [Web발신]안녕하세요 김팀장입니다!_x000D_우리 매장 매출을 성장시키는 치트키 제안드립니다._x000D__x000D_업무로 바쁘시더라도 시간내어주시며,_x000D_아까운 시간되지 않도록 알찬정보로 보답드리겠습니다._x000D_꼭 도움되시도록 맞춤형 는 내용입니다._x000D__x000D_누구나 다 아는 얘기지만, 누구나 다 할 수 없습니다. _x000D_대표님께서 혼자 하실 수 없는 일들 제가 모두 해드릴것입니다. _x000D_함께 매장을 발전시키고, 성장함에 있어 제가 앞장서 가장 큰 힘이 되도록 조력할것입니다. _x000D__x000D_필요하시면 <상담요청>이라고 문자 남겨주세요_x000D_순차적으로 연락드리겠습니다._x000D__x000D_저는 8년차 솔루션 운영 담당자 입니다. _x000D_300만명의 고객관리를 진행하고 있으며, 다양한 분야의 점주님들의 니즈를 맞춰 드리기위해 노력해왔습니다. _x000D_제가 제안드리는 솔루션은 매장에 꼭 필요한 솔루션 이라고 ?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen2(x):\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            f\"### 프롬프트: {PROMPT_TEXT}\\n\\n ### 질문: {x}\\n\\n### 답변:\",\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ),\n",
    "        max_new_tokens=1024,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(tokenizer.decode(gened[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2('(광고)[라이프해킹스쿨] 단 5일만에 쿠팡 셀러가 될 수 있습니다.창고, 홈페이지, 직원도 필요 없습니다.퇴근 후, 온라인 쿠팡 셀러가 되어 월급만큼 벌어보세요!쿠팡 셀러가 되기 위한 유일한 조건, 하루 1 시간씩, 5일만 투자하세요. (무료 교육)▼ 쿠팡 셀러되기 무료 신청 ▼  https://bit.ly/3tFUVEI 라이프해킹 스쿨이 회원님을 무료로 쿠팡 셀러로 만들어 드립니다.■ 누구든 할 수 있는 위한 친절한 가이드■ 업로드 공식부터 판매를 만드는 모든 과정 공개■ 혼자서는 결코 알 수 없는 Top 셀러의 노하우 전수■ 실습을 통한 판매 능력 배양5일 만에 온라인 셀러가 될 수 있는 절호의 기회를 놓치지 마세요!▼ 쿠팡 셀러되기 무료 신청 ▼  https://bit.ly/3tFUVEI무료거부 080')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2(\"[Web발신](광고)동전주를 아십니까?_x001D_　_x000D_'동전주' 를 아십니까?_x000D_소액1000원 주식들을 _x000D_동전주라고 합니다._x000D__x000D_140개이상 코스피,코스닥_x000D_종목의 동전주가 거래되고 _x000D_있다는걸 알고 계신가요?_x000D__x000D_라덕연 사태이후_x000D_세력들은 어디로 갔을까요?_x000D__x000D_▽▽동전주 매집 종목 확인▽▽_x000D_https://open-kakao.app/alsk_x000D_https://open-kakao.app/alsk_x000D_△△동전주 매집 종목 확인△△_x000D__x000D_지금 30명 참가 가능!_x000D__x000D_현재 주식시장에_x000D_진입하려는 개미군단들이_x000D_많은 동전주 시장으로_x000D_헤쳐모여 하고 있습니다._x000D__x000D_한화생명 088350_x000D_600원>>2580원_x000D_430% 폭등!!_x000D__x000D_한국ANKOR유전 152550_x000D_22원>>현재가 650원_x000D_2950% 폭등!! _x000D__x000D_과연 우연인가요?_x000D_대한민국 주식시장엔_x000D_우연은 없습니다._x000D__x000D_\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nospam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
